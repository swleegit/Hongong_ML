{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYbZrV6nuFPLkb+zIDscGE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swleegit/Hongong_ML/blob/main/05_02%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D%EA%B3%BC_%EA%B7%B8%EB%A6%AC%EB%93%9C_%EC%84%9C%EC%B9%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 검증세트(validation set)\n",
        "- 테스트 세트로 모델을 검증하다보면 모델이 테스트 세트에 맞춰지게 된다. 모델을 판단하는 척도의 의미가 사라지게 된다.\n",
        "\n",
        "- 훈련세트와 테스트세트의 점수 비교를 통해 과대, 과소적합을 판단할 수 있음\n",
        "\n",
        "- 테스트 세트는 마지막 검증시 딱 한번만 사용하고 훈련세트를 또 나누어서 과대, 과소적합을 판단하면서 진행한다.\n",
        "<img src = \"https://drive.google.com/uc?id=1Kr15JSSY96XSdAIPwB0ddiw1w5v_URM8\">\n",
        "\n",
        "\n",
        "- 보통 20~30%를 테스트세트와 검증세트로 떼어 놓는다. 하지만 문제에 따라 다르다. 훈련데이터가 아주 많다면 단 몇%만 떼어 놓아도 전체 데이터를 대표하는데 문제가 없다.\n",
        "\n"
      ],
      "metadata": {
        "id": "NvYuFXpj-bR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련세트에서 모델을 훈련하고 검증세트로 모델을 평가한다. 이런식으로 테스트하고 싶은 매개변수를 바꿔가며 가장 좋은 모델을 고른다.  \n",
        "그다음 이 매개변수를 사용해 훈련세트와 검증세트를 합쳐 전체 훈련데이터에서 모델을 다시 훈련한다.  \n",
        "그리고 마지막에 테스트 세트에서 최종 점수를 평가한다."
      ],
      "metadata": {
        "id": "OrHLVAl5AOJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "wine = pd.read_csv(\"https://bit.ly/wine_csv_data\")"
      ],
      "metadata": {
        "id": "Vv9aseJ3AkyT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n"
      ],
      "metadata": {
        "id": "KYjQ_q2aAswK"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split\\\n",
        "(data, target, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "cB8TwMv5A8nJ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_input, train_target을 다시 train_test_split으로 훈련세트와 검증세트로 분할한다.\n",
        "sub_input, val_input, sub_target, val_target = train_test_split\\\n",
        "(train_input, train_target, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "Ilt_PDX5BK9p"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sub_input.shape, val_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2GO3fETBbDS",
        "outputId": "e37155b5-a4ad-4a8a-c934-1568e8999ca3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4157, 3) (1040, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련세트와 검증세트(validation set)으로 모델을 훈련하고 평가\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state = 42)\n",
        "dt.fit(sub_input, sub_target)\n",
        "print(dt.score(sub_input, sub_target))\n",
        "print(dt.score(val_input, val_target))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxHEqQC7Bz7F",
        "outputId": "ac35e234-8d3e-461e-c9c1-b2bcca1e66c6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9971133028626413\n",
            "0.864423076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 교차검증(cross validation)\n",
        "- 검증세트를 만드느라 훈련세트가 줄었다. 보통 많은 데이터를 훈련에 사용할수록 좋은 모델이 만들어진다. 그렇다고 검증세트를 너무 조금 떼어 놓으면 검증점수가 들쭉날쭉하고 불안정하다.\n",
        "- 이럴때 교차검증을 이용하면 안정적인 검증점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있다.\n",
        "\n",
        "- 교차검증은 검증 세트를 떼어 내어 평가하는 과정을 여러번 반복한다. 그다음 이 점수를 평균하여 최종 검증 점수를 얻는다. \n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1ltKpIoF0SC5lgDeksX3KozFXc2IUKs0a\">\n",
        "\n",
        "\n",
        "- k-fold cross validation  \n",
        "훈련 세트를 k부분으로 나눠서 교차 검증을 수행하는 것. 보통은 5나 10이다.\n",
        "\n",
        "- 이렇게 하면 데이터의 80~90%까지 훈련에 사용할 수 있다. 검증세트가 줄얻들지만 각 폴드에서 계산한 검증 점수를 평균하기 때문에 안정된 점수로 생각할 수 있다.\n",
        "\n",
        "- 사이킷런에는 cross_validate()라는 교차 검증 함수가 있다.\n",
        "- 평가할 모델 객체를 첫 번째 매개변수로 전달하고 앞에서 처럼 직접 검증세트를 떼어 내지 않고 훈련세트 전체를 cross_validate()함수에 전달한다.(훈련세트와 테스트 세트를 나누는 과정은 필요)\n",
        "\n",
        "- scoring 매개변수 : 검증에 사용할 평가 지표를 지정할 수 있다. 기본적으로 분류 모델은 정확도 'accuracy', 회귀 모델은 결정계수를 의미하는 'r2'\n",
        "\n",
        "- cv 매개변수에 교차 검증 폴드 수나 스플리터 객체를 지정할 수 있다. \n",
        "\n",
        "- return_train_score매개변수를 True로 지정하면 훈련세트의 점수도 반환한다(원래는 검증세트 점수만 반환함) 기본값은 False\n",
        "\n",
        "\n",
        "- 참고 : cross_validate()함수의 전신인 cross_val_score()이 있다. 이 함수는 cross_validate()함수의 결과중에서 test_score만 반환한다."
      ],
      "metadata": {
        "id": "4TBIq5_NCYXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "scores = cross_validate(dt, train_input, train_target)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF1d6mICEWDb",
        "outputId": "3ae155d2-6580-4490-c9cb-73f76686c61a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.00881243, 0.01040554, 0.00805163, 0.00749922, 0.01015949]), 'score_time': array([0.00087023, 0.00110698, 0.00084901, 0.00078535, 0.00130558]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_validatie()라는 함수는 fit_time, score_time, test_score키를 가진 딕셔너리를 반환한다.  \n",
        "처음 2개의 키는 각각 모델을 훈련하는 시간과 검증하는 시간을 의미  \n",
        "각 키마다 5개의 숫자(값)이 있다.  \n",
        "cross_validatie()함수는 기본적으로 5-폴드 교차 검증을 수행하기 때문이다.  \n",
        "cv 매개변수에서 폴드 수를 바꿀 수도 있다.  \n",
        "교차 검증의 최종 점수는 test_score키에 담긴 5개의 점수를 평균하여 얻을 수 있다. 이름은 test_score이지만 테스트 세트를 이용한 점수가 아니라 검증세트를 이용한 점수이다! \n"
      ],
      "metadata": {
        "id": "zn8GvMdbEilv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5DkdnDWFIh7",
        "outputId": "c637408c-d248-4860-ca30-ee03e631f57f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.855300214703487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한 가지 주의할 점은 cross_validate()는 훈련세트를 섞어 폴드를 나누지 않는다.  \n",
        "앞서 train_test_split()함수로 전체 데이터를 섞은 후 훈련세트를 준비했기 때문에 따로 섞을 필요가 없다.  \n",
        "하지만 만약 교차 검증을 할때 훈련세트를 섞으려면 분할기(splitter)를 지정해야한다.  \n",
        "사이킷런의 분할기는 교차 검증에서 폴드를 어떻게 나눌지 결정해준다.  \n",
        "corss_validate()함수는 기본적으로 회귀 모델의 경우 KFOLD분할기를 사용하고 분류 모델일 경우 타깃 클래스를 골구로 나누기 위해 StratifiedKFold를 사용한다.  \n",
        "\n",
        "- cross_validate()함수에 모델을 첫번째 매개변수로 전달하는데 (이때 모델에는 이미 내가 매개변수를 지정해 놓은 상태) 이 모델이 회귀냐 분류냐에 따라 만약 splitter을 사용한다면 cross_validate()함수의 매개변수 cv가 달라진다는 의미(splitter을 미리 또 지정해놔야 한다)\n",
        "\n",
        "- splitter을 사용하면 검증세트와 훈련세트를 섞을 수 있다. "
      ],
      "metadata": {
        "id": "HAFcGxCtFOd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "scores = cross_validate(dt, train_input, train_target, cv = StratifiedKFold())\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTKQ_eK5GkTA",
        "outputId": "d9704b93-192e-49bf-9535-e23070bb840f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.855300214703487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#만약 훈련세트를 섞은 후 10-폴드 교차검증을 수행하려면 \n",
        "splitter = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
        "#cross_validate의 k , 섞기, random은 splitter 객체에 \n",
        "scores = cross_validate(dt, train_input, train_target, cv = splitter)\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFfvKycXHbE6",
        "outputId": "a0b9a4c2-ba21-414c-d5c8-514e107ee1fc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.01402521, 0.01009703, 0.01046801, 0.00935721, 0.00966144,\n",
              "        0.00978947, 0.00998902, 0.00937033, 0.0097096 , 0.01015329]),\n",
              " 'score_time': array([0.00101566, 0.00113153, 0.00122285, 0.00098872, 0.00113034,\n",
              "        0.00118613, 0.00108457, 0.00112057, 0.0010798 , 0.00112629]),\n",
              " 'test_score': array([0.84807692, 0.89423077, 0.87115385, 0.85576923, 0.86346154,\n",
              "        0.87884615, 0.87692308, 0.86319846, 0.87668593, 0.87475915])}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하이퍼파라미터 튜닝 \n",
        "모델 파라미터 : 머신러닝 모델이 학습하는 파라미터  \n",
        "하이퍼파라미터 : 모델이 학습할 수 없어서 사용자가 지정해야하는 것\n",
        "\n",
        "AutoML : 사람의 개입없이 하이퍼파리미터 튜닝을 자동으로 수행하는 기술  \n",
        "\n",
        "[중요]\n",
        "한 매개변수의 최적값을 찾고 다른 매개변수의 최적값을 찾는 방식은 안된다. 예컨대 결정트리에서 max_depth의 최적값은 min_ssamples_split 매개변수의값이 바뀌면 함께 달라진다. 즉 이 두 매개변수를 동시에 바꿔가며 최적의 값을 찾아야한다.  \n",
        "\n",
        "위와 같은 과정은 GridSearchCV클래스를 활용한다.  이는 하이퍼파리미터 탐색과 교차검증을 한번에 수행  \n",
        "별도로 cross_validate()함수를 호출할 필요가 없다.  \n",
        "cross_validate()는 교차검증, suffle, random_state, k 지정, 모델 대입, 이때 모델에는 파라미터를 대입한 모델을 대입하는 것  \n",
        "중요파라미터를 찾기위해서는 for구문을 써서 cross_validate()를 해야함   \n",
        "이 과정을 이미 만들어놓음 GridSearchCV : 교차검증 + 최적의 하이퍼 파라미터 찾기  \n",
        "따라서 후보 파라미터를 값으로 대입해야함"
      ],
      "metadata": {
        "id": "XfhtDZj7InZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'min_impurity_decrease' : [0.0001,0.0002,0.0003,0.0004,0.0005]}\n",
        "gs = GridSearchCV(DecisionTreeClassifier(random_state = 42), params, n_jobs = -1) #결정트리 클래스 객체를 생성하자마자 바로 전달 \n",
        "\n"
      ],
      "metadata": {
        "id": "glKFzHEpJWdF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV의 cv(splitter?) 매개변수 기본값은 5다.  \n",
        "따라서 min_impurity_decrease 값마다 5-폴드 교차 검증을 수행한다. 결국 5*5 = 25개의 모델을 훈련한다.(만약 gridsearch 없으면 for과 cross_validate()로 구현)  \n",
        "많은 모델을 훈련하기 때문에 GridSearchCV클래스의 n_jobs 매개변수에서 병렬 실행에 사용할 cpu코어 수를 지정한다.  \n",
        "n_jobs = 1 기본값, -1로 지정하면 시스템에 있는 모든 코어를 사용한다\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sjMeAX3vN3P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gs.fit(train_input, train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZjVHG5Q8Mo",
        "outputId": "c51ba2dc-197a-4ce7-c708-3ddb4814c7eb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
              "             param_grid={'min_impurity_decrease': [0.0001, 0.0002, 0.0003,\n",
              "                                                   0.0004, 0.0005]})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_validate의 경우 for을 활용하여 최적의 하이퍼파리머터를 찾았다고 하자. 그러면 전체 훈련세트로 모델을 해당 매개변수로 다시 만들어야한다.  \n",
        "\n",
        "하지만 gridsearch의 경우 훈련이 끝나면 25개의 모델 중에서 검증점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련세트에서 자동으로 다시 모델을 훈련한다.   \n",
        "이 모델은 gs객체의 best_estimator_속성에저장되어 있다.  \n",
        "\n",
        "grid search 매개변수  \n",
        "첫번째 매개변수로는 그리드 서치를 수행할 모델 객체를 전달, 두번째 매개변수에는 탐색할 모델의 매개변수와 값을 전달  \n",
        "scoring, cv, n_jobs, return_train_score 매개변수는 cross_validate()함수와 동일 "
      ],
      "metadata": {
        "id": "kHQ5_bMnRD94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = gs.best_estimator_ \n",
        "#최고의 점수를 받은 매개변수로 gs에서 지정한 학습모델(결정트리)을 전체학습데이터를 활용해서 학습(fit)한것을 \n",
        "#dt객체에 넘기것 \n",
        "print(dt.score(train_input,train_target)) #그래서 바로 score을 사용할 수 있다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoP6w3AYR34l",
        "outputId": "a14ec27f-2b78-44ba-a92c-3dbc24f8cf87"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9615162593804117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#그리더 서치로 찾은 최적의 매개변수는 best_params_속성에 저장되어 있다.\n",
        "print(gs.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x40sX0VR81f",
        "outputId": "ccb883f1-1b9f-4ba6-82e6-48fa78fae5c1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_impurity_decrease': 0.0001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#각 매개변수에서 수행한 교차검증의 평균점수는 cv_results_속성의 'mean_test_score'키에 저장되어 있다.\n",
        "print(gs.cv_results_['mean_test_score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Z3IgHfSdpb",
        "outputId": "e46122d1-03f5-4789-af9a-1f48f953c9b3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#배열에서 가장 큰 값의 인덱스를 추출하는 함수\n",
        "best_index = np.argmax(gs.cv_results_['mean_test_score'])\n",
        "print(gs.cv_results_['params'][best_index])\n",
        "#gs.cv_results_는 딕셔너리 구조, 그중 key가 'params'인것은 value를 리스트로 가지고 있고 best_index로 뽑아낸것"
      ],
      "metadata": {
        "id": "s_8ij6RDSxFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444cd805-ddab-44c6-8b80-b3849c7b7ce4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_impurity_decrease': 0.0001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 먼저 탐색할 매개변수를 지정한다.\n",
        "2. 그다음 훈련 세트에서 그리드 서치를 수행하여 최상의 평균 검증 점수가 나오는 매개변수 조합을 찾는다. 이 조합은 그리드 서치 객체에 저장된다.\n",
        "3. 그리더 서치는 최상의 매개변수에서 (교차 검증에 사용한 훈련세트가 아니라) 전체 훈련세트를 사용해 최종 모델을 훈련한다. 이 모델도 그리드 서치 객체에 저장된다.(best_estimator_)"
      ],
      "metadata": {
        "id": "K4wvkfWeAjm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#min_impurity_decrease : 노드를 분할하기 위한 불순도 감소 최소량 지정 \n",
        "#max_depth ㅍ누기 위한 최소 샘플 수 \n",
        "\n",
        "#파라미터는 딕셔너리 형태로 지정 \n",
        "params = {'min_impurity_decrease' : np.arange(0.0001, 0.001, 0.0001) #: 9\n",
        ",'max_depth' : range(5,20,1), #5,6,7,...19 : 15\n",
        "'min_samples_split' : range(2,100,10)} #2,12,22...92 : 10\n",
        "#arange : 실수 ok, range : only 정수 \n",
        "#경우의 수 9*15*10 = 1350, kfold : 5 : 6750개"
      ],
      "metadata": {
        "id": "vTafn0t8Bkcw"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs = GridSearchCV(DecisionTreeClassifier(random_state = 42), params, n_jobs = -1)\n",
        "gs.fit(train_input, train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3sApYJxDYof",
        "outputId": "64a77331-ec9c-4625-cbf8-23b8964196d5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
              "             param_grid={'max_depth': range(5, 20),\n",
              "                         'min_impurity_decrease': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,\n",
              "       0.0009]),\n",
              "                         'min_samples_split': range(2, 100, 10)})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gs.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yARRSdj8Diw8",
        "outputId": "8b0375b8-0da1-4b72-8194-32da6a7c2e1a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(gs.cv_results_['mean_test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86lGYz6QDte-",
        "outputId": "c86d5285-c755-4233-9d6b-8c05e0f66068"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8683865773302731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV클래스를 사용하니 매개변수를 일일이 바꿔가며 교차 검증을 수행하지 않고 원하는 매개변수 값을 나열하면 자동으로 교차검증을 수행해서 최상의 매개변수를 찾을 수 있다."
      ],
      "metadata": {
        "id": "a76NdpicDzwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤서치(random search)\n",
        "- 그리드 서치에서 매개변수의 간격에 대한 근거가 없다. 이보다 더 좁거나 넓은 간격으로 시도할 필요가 있다.\n",
        "\n",
        "- 매개변수의 값이 수치일 때의 값의 범위나 간격을 미리 정하기 어려운 경우가 많다.\n",
        "\n",
        "- 또 너무 많은 매개변수 조건이 있어 그리드 서치 수행 시간이 오래 걸릴 수 있다. \n",
        "- 이럴 때 랜덤서치를 사용하면 좋다."
      ],
      "metadata": {
        "id": "ci7T8n5kEbBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 랜덤서치에는 매개변수의 값의 목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있는 확률 분포 객체를 전달한다.\n",
        "\n",
        "- 싸이파이(scipy)는 핵심 과학 라이브러리 중 하나로 적분, 보간, 선형 대수, 확률 등을 포함한 수치 계산 전용 라이브러리"
      ],
      "metadata": {
        "id": "JV2Sv4PiE9Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import uniform, randint"
      ],
      "metadata": {
        "id": "egTPUaKhFG0l"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- scipy의 stats 서브 패키지에 있는 uniform과 randint클래스는 모두 주어진 범위에서 고르게 값을 뽑는다. = 균등 분포에서 샘플링한다.  \n",
        "값의 개수가 균등하기보단, 주어진 범위에서 각 구간별 데이터의 개수가 균등하다 = 각 구간별 확률이 균등하게 샘플링하는 것 \n",
        "\n",
        "- randint는 정수값을 뽑고\n",
        "- uniform은 실수값을 뽑는다"
      ],
      "metadata": {
        "id": "UK8Zq0xCFWYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgen = randint(0,10) #0과 10범위 내에서 정수를 고르게 샘플링 하도록 하는 객체 만듬 \n",
        "rgen.rvs() #10개를 균등하게 샘플링 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VhrptJTF-AS",
        "outputId": "3326c277-0be4-45ed-d72a-eec9d711652c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(rgen.rvs(555), return_counts=True) #고유값, 개수까지 출력\n",
        "#0~9범위(전체범위)에서 구간별 범위(0~1,1~2...)의 값의 개수가 비슷하게 샘플링 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbB_ndpDGD3f",
        "outputId": "80266839-7474-473c-812b-6f4b7211d77b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " array([68, 57, 58, 63, 50, 48, 40, 57, 48, 66]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ugen = uniform(0,100)\n",
        "np.unique(ugen.rvs(100), return_counts = True)\n",
        "#0과1사이 실수(전체범위)에서 구간별(정확이 각 구간의 크기는 모르지만)확률이 비슷하도록 값을 샘플링"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0R2bvpoGf5W",
        "outputId": "32bf3822-8fb8-43a1-c258-fa731d4d5545"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.0451248 ,  2.50831241,  3.21326628,  3.48224985,  4.08087597,\n",
              "         4.22898891,  5.85620122,  5.94291316,  8.40547063,  9.57377326,\n",
              "         9.70222784, 10.30914264, 10.94788174, 12.11316948, 13.05430455,\n",
              "        14.33249631, 15.24326079, 17.66056432, 18.16822543, 18.97488312,\n",
              "        20.31435758, 20.33610126, 22.19116936, 24.16595395, 24.55006992,\n",
              "        25.30586593, 26.0526184 , 26.14326418, 30.71081271, 31.35937187,\n",
              "        31.5542489 , 32.89294443, 34.95143772, 35.65449827, 37.41213323,\n",
              "        37.76824878, 38.49607655, 38.62453757, 39.92714545, 42.88925826,\n",
              "        45.77509346, 45.86810243, 48.58080223, 51.01578038, 51.56833299,\n",
              "        51.7185875 , 51.87308963, 52.11843455, 52.35446666, 52.70750349,\n",
              "        54.1187599 , 57.21878207, 57.56522065, 57.67490645, 61.21334821,\n",
              "        61.79974597, 62.58709301, 63.96387215, 64.1759202 , 67.17705714,\n",
              "        68.66870983, 68.86874046, 69.89264878, 70.07511381, 70.80543737,\n",
              "        71.84648492, 72.01551742, 75.9967879 , 76.1626864 , 76.16316945,\n",
              "        76.87562474, 77.63084712, 77.83838248, 80.03940966, 80.25957603,\n",
              "        80.45062651, 80.63551069, 82.71277092, 83.36357573, 84.01026694,\n",
              "        84.07137394, 84.18802954, 84.4183421 , 86.31651322, 86.50240375,\n",
              "        86.76671622, 87.29593968, 87.84098406, 90.5322759 , 90.85235359,\n",
              "        90.88316684, 93.08387016, 93.88950156, 93.99645427, 95.57458449,\n",
              "        96.39631956, 96.44271485, 97.75457801, 98.63999718, 99.80298327]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 랜덤서치에 randint와 uniform 클래스 객체를 넘겨주고 총 몇번을 샘플링해서 최적의 매개변수를 찾으라고 명령. 샘플링 횟수는 시스템 자원이 허락하는 범위 내에서 최대한 크게 하는 것이 좋다.\n"
      ],
      "metadata": {
        "id": "37LU3_K9GsHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 탐색할 매개변수의 딕셔너리를 만들자\n",
        "- min_samples_leaf 매개변수 : 리프 노드가 되기 위한 최소 샘플의 개수, 어떤 노드가 분할하여 만들어질 자식 노드의 샘플 수가 이 값보다 작을 경우 분할하지 않는다. "
      ],
      "metadata": {
        "id": "EKexd1ZsJ4_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'min_impurity_decrease': uniform(0.0001, 0.001),\n",
        "          'max_depth': randint(20, 50),\n",
        "          'min_samples_split': randint(2, 25),\n",
        "          'min_samples_leaf': randint(1, 25),\n",
        "          }"
      ],
      "metadata": {
        "id": "y4orADglKE8R"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# gs = RandomizedSearchCV(DecisionTreeClassifier(random_state = 42), params,\\\n",
        "#                         n_iter = 100, n_jobs = -1, random_state = 42)\n",
        "# gs.fit(train_input, train_target)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "gs= RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, \n",
        "                        n_iter=100, n_jobs=-1, random_state=42)\n",
        "gs.fit(train_input, train_target)\n",
        "\n",
        "#각 매개변수 100개 sampling 해서 경우의수 100^^4한다는 의미가 아니라\n",
        "#각 매개변수 균등분포로 정해진 범위안에서 분포해있는데 전체 조합으로 100개 뽑아서 실시한다는것\n",
        "#gridsearch보다 넓거나 좁은간격으로 넓은 범위의 매개변수에서 적은 시도로 탐색 가능\n",
        "#컴퓨터 자원이 허락하는한 n_iter이 높으면 좋은 것 \n",
        "#random_state = 42는 100개를 뽑는 순서에 관련된 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "Bh8QpttMLHoT",
        "outputId": "e279f490-2f5c-4a54-86e6-41c301960c00"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 248, in set_params\n    \"with `estimator.get_params().keys()`.\" % (key, self)\nValueError: Invalid parameter min_sampels_leaf for estimator DecisionTreeClassifier(max_depth=26,\n                       min_impurity_decrease=0.0008965429868602329,\n                       random_state=42). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-da6cb550090c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m gs= RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, \n\u001b[1;32m      9\u001b[0m                         n_iter=100, n_jobs=-1, random_state=42)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#각 매개변수 100개 sampling 해서 경우의수 100^^4한다는 의미가 아니라\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter min_sampels_leaf for estimator DecisionTreeClassifier(max_depth=26,\n                       min_impurity_decrease=0.0008965429868602329,\n                       random_state=42). Check the list of available parameters with `estimator.get_params().keys()`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(gs.best_params_)  \n",
        "print(np.max(gs.cv_results['mean_test_score']))  \n",
        "최적의 모델은 이미 전체 훈련세트 (train_input, train_target)로 훈련되어 best_estimator_속성에 저장되어 있다.  \n",
        "dt = gs.best_estimator_  \n",
        "print(dt.score(test_input, test_target))  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jSzvWyfvNQqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤서치는 연속된 매개변수 값을 탐색할 때 유용하다. 탐색할 값을 직접 나열하는 것이 아니라 탐색 값을 샘플링할 수 있는 확률 분포 객체를 전달한다. 지정됫 횟수만큼 샘플링하여 교차 검증을 수행하기 때문에 시스템 자원이 허락하는 만큼 탐색량을 조절 할 수 있다.   "
      ],
      "metadata": {
        "id": "iY4SMuOiZYBI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4A2Ln15aFsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}